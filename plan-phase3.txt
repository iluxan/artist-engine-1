# EVENT DISCOVERY AGENT - PHASE 3 PLAN

## Overview
Phase 3 focuses on **intelligent source discovery** using OpenAI's GPT API to find real, verified sources where people publish their events. This replaces the heuristic-based URL generation from Phase 1/2 with actual web research and validation.

## Goals
1. Integrate OpenAI API for intelligent web search and analysis
2. Discover real, verified sources for each person
3. Validate that sources actually exist and contain event information
4. Store source metadata (last checked, verification status)
5. Provide confidence scoring based on actual content analysis

## Core Feature: AI-Powered Source Discovery

### The Problem with Current Implementation
Currently, `sourceDiscovery.js` generates URLs using patterns like:
- `https://twitter.com/johnsmith` (guessed handle)
- `https://www.johnsmith.com` (guessed domain)
- Generic event platform URLs

**Issues:**
- Most generated URLs don't exist
- No verification of actual content
- Low accuracy and usefulness
- Wastes user time checking invalid sources

### The Solution: GPT-Powered Web Research

Use OpenAI API to:
1. Search for the person across the web
2. Identify official accounts and profiles
3. Verify sources actually exist
4. Analyze content to confirm it's event-related
5. Extract additional metadata (follower counts, last post date, etc.)

## Architecture

### New Dependencies
```json
{
  "openai": "^4.0.0",
  "dotenv": "^16.0.0"
}
```

### Environment Variables (.env)
```
OPENAI_API_KEY=sk-...
```

### New Module: aiSourceDiscovery.js

```javascript
// Core functions:
- discoverSourcesWithAI(personName, personDescription)
- verifySourceExists(url)
- analyzeSourceContent(url, personName)
- extractSourceMetadata(url)
```

## Implementation Strategy

### Multi-Step Discovery Process

#### Step 1: Initial Web Search (GPT-4)
Prompt GPT to search for:
- Official website
- Social media accounts (Twitter, Mastodon, Instagram)
- IGNORE THESE - Event platform profiles (Eventbrite, Songkick, Bandsintown, Dice)
- publishers with event announcements

**Approach:** Use GPT-4 with web browsing capability OR use GPT-4 to generate search queries, then use a search API (Google Custom Search, Bing Search, Brave Search)

#### Step 2: URL Verification
For each discovered URL:
1. Check if URL is accessible (HTTP request)
2. Verify domain exists and responds
3. Check for rate limits or blocks
4. Store HTTP status and headers

#### Step 3: Content Analysis (GPT-4 Text)
For verified URLs:
1. Fetch page content (HTML)
2. Extract text and relevant metadata
3. Use GPT-4 to analyze:
   - Is this the correct person?
   - Does this source post event information?
   - What types of events? (concerts, talks, book signings, etc.)
   - How frequently are events posted?
   - Last event announcement date
4. Page back several pages, try to find an actual event or two

#### Step 4: Confidence Scoring
Based on analysis, assign confidence:
- **High (90-100%)**: Official website with events calendar, verified social account
- **Medium (60-89%)**: Social media account, event platform profile with activity
- **Low (30-59%)**: Unverified or indirect sources
- **Very Low (<30%)**: Suspicious or likely incorrect

#### Step 5: Metadata Extraction
Store additional data:
- Source type (website, twitter, instagram, etc.)
- Follower/subscriber count
- Last post/update date
- Event posting frequency
- Platform-specific IDs (Twitter handle, Instagram username, etc.)

## API Endpoints

### New/Modified Endpoints

```
POST /api/people/:id/discover-ai
- Trigger AI-powered source discovery
- Body: { personDescription?: string }
- Returns: { sources: [...], analysis: {...} }

GET /api/sources/:id/verify
- Re-verify and analyze an existing source
- Returns: { verified: boolean, analysis: {...} }

POST /api/sources/:id/refresh-metadata
- Update source metadata (follower count, last post, etc.)
- Returns: { metadata: {...} }
```

## Database Schema Updates

### ALTER sources table
Add new columns:
```sql
- verified (BOOLEAN DEFAULT false)
- verification_date (DATETIME)
- last_content_check (DATETIME)
- metadata (TEXT) -- JSON: follower count, last post date, etc.
- ai_confidence_score (INTEGER 0-100)
- ai_analysis_summary (TEXT)
- platform_id (TEXT) -- Twitter handle, Instagram username, etc.
```

## OpenAI API Integration

### Configuration
```javascript
const OpenAI = require('openai');
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
});
```

### Search Strategy

#### Option 1: GPT-4 with Function Calling + Web Search API
1. Use GPT-4 to generate targeted search queries
2. Execute searches via Google Custom Search API or Brave Search API
3. GPT-4 analyzes search results and extracts relevant URLs
4. Verify and analyze each URL

#### Option 2: GPT-4 with Web Browsing (if available)
1. Use GPT-4 with browsing capability
2. Direct GPT to search for the person and find official sources
3. GPT returns structured JSON with discovered sources

#### Option 3: Hybrid Approach (Recommended)
1. Use web search API for initial discovery
2. Use GPT-4 to analyze and verify results
3. Use GPT-4 Vision for screenshot analysis if needed
4. Fall back to traditional scraping for structured data

### Prompt Engineering

**Discovery Prompt Template:**
```
You are helping discover official event sources for {personName}.
{personDescription}

Find the following information:
1. Official website (with events page if available)
2. Twitter/X account (verified if possible)
3. Instagram account
4. Facebook page
5. Event platform profiles (Eventbrite, Songkick, Bandsintown, Dice, etc.)
6. YouTube channel
7. Any other official sources where they announce events

For each source:
- Provide the exact URL
- Explain why you believe this is the correct person
- Note if the account is verified
- Indicate if events are posted there

Return results as JSON:
{
  "sources": [
    {
      "type": "twitter",
      "url": "https://twitter.com/...",
      "verified": true,
      "confidence": "high",
      "reasoning": "Verified account with 1M followers, regularly posts tour dates"
    }
  ]
}
```

**Verification Prompt Template:**
```
Analyze this webpage content for {personName}:
URL: {url}

Content: {pageContent}

Questions:
1. Is this page about the correct person?
2. Does this source post event announcements?
3. What types of events are posted? (concerts, talks, appearances, etc.)
4. How often are events posted?
5. When was the last event announcement?

Provide confidence score (0-100) and reasoning.
```

## Implementation Steps

### Step 1: Setup (2-3 hours)
1. Install OpenAI SDK and dotenv
2. Create .env file with API key (add to .gitignore)
3. Set up OpenAI client configuration
4. Update database schema with new columns
5. Create aiSourceDiscovery.js module

### Step 2: Basic AI Discovery (4-5 hours)
1. Implement basic GPT-4 discovery function
2. Create prompts for source discovery
3. Parse GPT responses (JSON format)
4. Handle errors and rate limits
5. Test with sample persons

### Step 3: URL Verification (3-4 hours)
1. Implement HTTP verification
2. Handle redirects and errors
3. Check robots.txt compliance
4. Store verification results
5. Add retry logic

### Step 4: Content Analysis (5-6 hours)
1. Fetch and parse webpage content
2. Extract relevant text/metadata
3. Use GPT-4 for content analysis
4. Calculate confidence scores
5. Store analysis results

### Step 5: API Integration (3-4 hours)
1. Create new API endpoint for AI discovery
2. Update existing discover endpoint
3. Add verification endpoint
4. Add metadata refresh endpoint
5. Test API responses

### Step 6: Frontend Updates (4-5 hours)
1. Update "Discover" button to use AI discovery
2. Show discovery progress (loading states)
3. Display confidence scores and reasoning
4. Show verification status badges
5. Add "Refresh" option for sources

### Step 7: Optimization (3-4 hours)
1. Implement caching for API responses
2. Add rate limiting for OpenAI calls
3. Batch processing for multiple people
4. Cost tracking and limits
5. Error handling and fallbacks

### Step 8: Testing & Polish (2-3 hours)
1. Test with various person types (musicians, authors, speakers)
2. Verify accuracy of discovered sources
3. Test edge cases (common names, international)
4. Add logging and monitoring
5. Update documentation

## Cost Considerations

### OpenAI API Pricing (as of 2024)
- GPT-4: ~$0.03 per 1K tokens (input), ~$0.06 per 1K tokens (output)
- Typical discovery: ~2K input tokens + 1K output tokens = ~$0.09 per person
- 100 discoveries = ~$9
- 1000 discoveries = ~$90

### Cost Optimization Strategies
1. Cache discovery results (don't re-discover same person)
2. Use GPT-3.5-turbo for verification (cheaper)
3. Batch analyze multiple URLs in single request
4. Set daily/monthly API spending limits
5. Offer "Fast" (AI) vs "Basic" (heuristic) discovery options

### Budget Recommendations
- Development/Testing: $10-20/month
- Light use (100 users, 10 discoveries each): $90/month
- Medium use (1000 users, 10 discoveries each): $900/month
- Consider usage limits per user (e.g., 10 discoveries per day)

## Alternative: Web Search API Integration

If OpenAI costs are too high, consider:

### Option A: Brave Search API
- Free tier: 2,000 queries/month
- Paid: $3 per 1,000 queries
- Returns search results, then use cheaper GPT-3.5 for analysis

### Option B: Google Custom Search API
- Free tier: 100 queries/day
- Paid: $5 per 1,000 queries
- More accurate search results

### Option C: SerpAPI
- $50/month for 5,000 searches
- Includes Google, Bing, Yahoo, etc.
- Easy integration

### Hybrid Strategy
1. Use search API to find candidate URLs ($0.003-0.005 per search)
2. Use GPT-3.5-turbo to analyze results ($0.002 per analysis)
3. Total cost: ~$0.01 per discovery (10x cheaper than GPT-4 only)

## Security Considerations

### API Key Management
- Store OpenAI API key in .env (never commit)
- Use environment variables in production
- Rotate keys regularly
- Monitor usage and set spending limits

### Rate Limiting
- Limit discoveries per user per day
- Queue requests during high traffic
- Implement exponential backoff for retries

### Content Safety
- Filter out inappropriate content
- Validate URLs before visiting
- Sanitize all user inputs
- Handle malicious websites gracefully

## Success Criteria
- [ ] AI-powered discovery finds 80%+ accurate sources
- [ ] At least 3 verified sources per person on average
- [ ] Verification process completes in <30 seconds
- [ ] Confidence scores correlate with actual accuracy
- [ ] API costs stay under budget limits
- [ ] User can understand why each source was selected
- [ ] System handles rate limits and errors gracefully

## Future Enhancements (Phase 4)
- Automatic re-verification on schedule
- Learn from user feedback (mark sources as incorrect)
- Discover new platforms automatically
- Multi-language support for international artists
- Integration with social media APIs (Twitter, Instagram official APIs)
- Event parsing from discovered sources (original Phase 3 plan)

## Testing Plan

### Unit Tests
- OpenAI API integration
- URL verification logic
- Content parsing
- Confidence scoring algorithm

### Integration Tests
- Full discovery workflow
- Database updates
- API endpoints
- Error handling

### Manual Testing Scenarios
1. Discover sources for well-known musician (e.g., Taylor Swift)
2. Discover sources for obscure local artist
3. Test with author names
4. Test with common names (e.g., "John Smith")
5. Test with international characters
6. Test error cases (invalid names, API failures)

### Acceptance Testing
- Compare AI-discovered sources vs manual research
- Measure accuracy, precision, recall
- Get user feedback on source quality
- Verify cost per discovery stays within budget

## Timeline
- Setup: 2-3 hours
- Basic AI Discovery: 4-5 hours
- URL Verification: 3-4 hours
- Content Analysis: 5-6 hours
- API Integration: 3-4 hours
- Frontend Updates: 4-5 hours
- Optimization: 3-4 hours
- Testing & Polish: 2-3 hours

**Total: 26-34 hours** (3-4 full days of work)

## Notes
- Start with GPT-4 for accuracy, optimize to GPT-3.5-turbo later
- Consider offering both "AI Discovery" (paid feature) and "Basic Discovery" (free, heuristic)
- Monitor token usage closely during development
- Build cost tracking dashboard for admin
- Consider using LangChain for easier OpenAI integration
- Store all API responses for debugging and improvement